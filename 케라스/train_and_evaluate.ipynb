{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb291b62b1aa"
   },
   "source": [
    "# Training and evaluation with the built-in methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d4ac441b1fc"
   },
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:48.305955Z",
     "iopub.status.busy": "2021-04-07T17:58:48.305368Z",
     "iopub.status.idle": "2021-04-07T17:58:53.785129Z",
     "shell.execute_reply": "2021-04-07T17:58:53.785508Z"
    },
    "id": "0472bf67b2bf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c16fe7fd6a6c"
   },
   "source": [
    "## 시작하기\n",
    "\n",
    "이 안내서는 훈련 및 유효성 검증을 위해 내장 API를 사용할 때의 훈련, 평가 및 예측 (추론) 모델 (예 : `model.fit()` , `model.evaluate()` , `model.predict()` )에 대해 설명합니다.\n",
    "\n",
    "고유한 훈련 단계 함수를 지정하면서 `fit()`을 사용하려면 <a href=\"https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\" data-md-type=\"link\">\" `fit()`에서 이루어지는 작업 사용자 정의하기\"</a> 가이드를 참조하세요.\n",
    "\n",
    "고유한 훈련 및 평가 루프를 처음부터 작성하려면 [\"처음부터 훈련 루프 작성\"](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/) 안내서를 참조하십시오.\n",
    "\n",
    "일반적으로, 내장 루프를 사용하든 직접 작성하든 관계없이 모델 훈련 및 유효성 검사는 모든 종류의 Keras 모델(순차 모델, Functional API로 작성된 모델 및 모델 하위 클래스화를 통해 처음부터 작성된 모델)에서 완전히 동일하게 작동합니다.\n",
    "\n",
    "이 가이드는 분산 교육에 대해서는 다루지 않습니다. 분산 교육에 대해서는 [멀티 GPU 및 분산 교육 안내서를](https://keras.io/guides/distributed_training/) 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e270faa413e"
   },
   "source": [
    "## API 개요 : 첫 번째 엔드 투 엔드 예제\n",
    "\n",
    "데이터를 모델의 내장 훈련 루프로 전달할 때는 **NumPy 배열**(데이터가 작고 메모리에 맞는 경우) 또는 **`tf.data Dataset` 객체**를 사용해야 합니다. 다음 몇 단락에서는 옵티마이저, 손실 및 메트릭을 사용하는 방법을 보여주기 위해 MNIST 데이터세트를 NumPy 배열로 사용하겠습니다.\n",
    "\n",
    "다음 모델을 고려해 보겠습니다 (여기서는 Functional API를 사용하여 빌드하지만 Sequential 모델 또는 하위 클래스 모델 일 수도 있음)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:53.792832Z",
     "iopub.status.busy": "2021-04-07T17:58:53.792213Z",
     "iopub.status.idle": "2021-04-07T17:58:55.407575Z",
     "shell.execute_reply": "2021-04-07T17:58:55.408010Z"
    },
    "id": "170a6a18b2a3"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6d5724a90ab"
   },
   "source": [
    "일반적인 엔드 투 엔드 워크 플로는 다음과 같이 구성되어 있습니다.\n",
    "\n",
    "- 학습\n",
    "- 원래 교육 데이터에서 생성 된 홀드 아웃 세트에 대한 유효성 검사\n",
    "- 테스트 데이터에 대한 평가\n",
    "\n",
    "이 예에서는 MNIST 데이터를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.413652Z",
     "iopub.status.busy": "2021-04-07T17:58:55.413065Z",
     "iopub.status.idle": "2021-04-07T17:58:55.758213Z",
     "shell.execute_reply": "2021-04-07T17:58:55.757663Z"
    },
    "id": "8b55b3903edb"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77a84eb1985b"
   },
   "source": [
    "훈련 구성(최적화 프로그램, 손실, 메트릭)을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.769921Z",
     "iopub.status.busy": "2021-04-07T17:58:55.769317Z",
     "iopub.status.idle": "2021-04-07T17:58:55.788128Z",
     "shell.execute_reply": "2021-04-07T17:58:55.787601Z"
    },
    "id": "26a7f1819796"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef28150b1eaa"
   },
   "source": [
    "`fit()`를 호출하여 데이터를 \"batch_size\" 크기의 \"배치\"로 분할하고 지정된 수의 \"epoch\"에 대해 전체 데이터세트를 반복 처리하여 모델을 훈련시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.792862Z",
     "iopub.status.busy": "2021-04-07T17:58:55.792230Z",
     "iopub.status.idle": "2021-04-07T17:59:00.616809Z",
     "shell.execute_reply": "2021-04-07T17:59:00.617243Z"
    },
    "id": "0b92f67b105e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3493 - sparse_categorical_accuracy: 0.9005 - val_loss: 0.2018 - val_sparse_categorical_accuracy: 0.9417\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 1s 836us/step - loss: 0.1615 - sparse_categorical_accuracy: 0.9514 - val_loss: 0.1264 - val_sparse_categorical_accuracy: 0.9636\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a1b698c6e39"
   },
   "source": [
    "반환되는 \"이력\" 객체는 훈련 중 손실 값과 메트릭 값에 대한 레코드를 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.625752Z",
     "iopub.status.busy": "2021-04-07T17:59:00.625141Z",
     "iopub.status.idle": "2021-04-07T17:59:00.628091Z",
     "shell.execute_reply": "2021-04-07T17:59:00.628463Z"
    },
    "id": "a20b8f5b9fcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3492700755596161, 0.16149932146072388],\n",
       " 'sparse_categorical_accuracy': [0.9004799723625183, 0.9514200091362],\n",
       " 'val_loss': [0.2018035352230072, 0.1263878047466278],\n",
       " 'val_sparse_categorical_accuracy': [0.9416999816894531, 0.9635999798774719]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6105b646df66"
   },
   "source": [
    "`evaluate()`를 통해 테스트 데이터에 대해 모델을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.632994Z",
     "iopub.status.busy": "2021-04-07T17:59:00.632410Z",
     "iopub.status.idle": "2021-04-07T17:59:00.894621Z",
     "shell.execute_reply": "2021-04-07T17:59:00.894161Z"
    },
    "id": "69f524a93f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 638us/step - loss: 0.1330 - sparse_categorical_accuracy: 0.9605\n",
      "test loss, test acc: [0.13297568261623383, 0.9605000019073486]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (3, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.74965737e-06, 8.84826434e-08, 5.76421386e-04, 2.88465060e-03,\n",
       "        1.55338808e-09, 4.32357911e-06, 9.35959643e-12, 9.96525109e-01,\n",
       "        1.13876536e-06, 5.56491659e-06],\n",
       "       [1.39887209e-06, 3.64981854e-04, 9.99455392e-01, 9.11674360e-05,\n",
       "        1.05993886e-11, 4.42212752e-07, 5.32452168e-06, 4.87348295e-09,\n",
       "        8.13002480e-05, 5.24931543e-10],\n",
       "       [1.96906194e-06, 9.92592096e-01, 9.26638604e-04, 1.83029589e-03,\n",
       "        4.58012073e-05, 8.07114775e-05, 1.57958493e-04, 3.52841988e-03,\n",
       "        7.56731431e-04, 7.94134103e-05]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f19d074eb88c"
   },
   "source": [
    "이제이 워크 플로의 각 부분을 자세히 검토하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3669f026d14"
   },
   "source": [
    "## `compile()` 메소드 : 손실, 메트릭 및 최적화 프로그램 지정\n",
    "\n",
    "`fit()` 으로 모델을 학습하려면 손실 함수, 최적화 프로그램 및 선택적으로 모니터링 할 일부 메트릭을 지정해야합니다.\n",
    "\n",
    "이것을 `compile()` 메소드의 인수로 모델에 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.903471Z",
     "iopub.status.busy": "2021-04-07T17:59:00.902774Z",
     "iopub.status.idle": "2021-04-07T17:59:00.912104Z",
     "shell.execute_reply": "2021-04-07T17:59:00.911681Z"
    },
    "id": "eb7a8deb494c"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4061c977ac3"
   },
   "source": [
    "`metrics` 인수는 목록이어야합니다. 모델에는 여러 개의 메트릭이있을 수 있습니다.\n",
    "\n",
    "모델에 여러 개의 출력이있는 경우 각 출력에 대해 서로 다른 손실 및 메트릭을 지정하고 모델의 총 손실에 대한 각 출력의 기여도를 조정할 수 있습니다. 이에 대한 자세한 내용은 **\"다중 입력, 다중 출력 모델로 데이터 전달\"** 섹션에서 확인할 수 있습니다.\n",
    "\n",
    "기본 설정에 만족하면 대부분의 경우 최적화, 손실 및 메트릭을 문자열 식별자를 통해 바로 가기로 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.920513Z",
     "iopub.status.busy": "2021-04-07T17:59:00.919946Z",
     "iopub.status.idle": "2021-04-07T17:59:00.924629Z",
     "shell.execute_reply": "2021-04-07T17:59:00.924967Z"
    },
    "id": "6444839ff300"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5493ab963254"
   },
   "source": [
    "나중에 재사용하기 위해 모델 정의와 컴파일 단계를 함수에 넣겠습니다. 이 안내서의 여러 예에서 여러 번 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.930518Z",
     "iopub.status.busy": "2021-04-07T17:59:00.929926Z",
     "iopub.status.idle": "2021-04-07T17:59:00.932021Z",
     "shell.execute_reply": "2021-04-07T17:59:00.931520Z"
    },
    "id": "31c3e3c70f06"
   },
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21b19c0a6a85"
   },
   "source": [
    "### 많은 내장 옵티 마이저, 손실 및 메트릭을 사용할 수 있습니다\n",
    "\n",
    "일반적으로 고유한 손실, 메트릭 또는 최적화 프로그램을 처음부터 새로 만들 필요가 없는데, Keras API에 필요한 것들이 이미 들어 있을 개연성이 높기 때문입니다.\n",
    "\n",
    "옵티마이저\n",
    "\n",
    "- `SGD()` (모멘텀이 있거나 없음)\n",
    "- `RMSprop()`\n",
    "- `Adam()`\n",
    "- 기타\n",
    "\n",
    "손실:\n",
    "\n",
    "- `MeanSquaredError()`\n",
    "- `KLDivergence()`\n",
    "- `CosineSimilarity()`\n",
    "- 기타\n",
    "\n",
    "메트릭\n",
    "\n",
    "- `AUC()`\n",
    "- `Precision()`\n",
    "- `Recall()`\n",
    "- 기타"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7abc0339980"
   },
   "source": [
    "### 관례 손실\n",
    "\n",
    "Keras로 커스텀 손실을 제공하는 두 가지 방법이 있습니다. 첫 번째 예는 입력 `y_true` 및 `y_pred` 를 받아들이는 함수를 만듭니다. 다음 예는 실제 데이터와 예측 간의 평균 제곱 오차를 계산하는 손실 함수를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.938634Z",
     "iopub.status.busy": "2021-04-07T17:59:00.938085Z",
     "iopub.status.idle": "2021-04-07T17:59:02.545087Z",
     "shell.execute_reply": "2021-04-07T17:59:02.544610Z"
    },
    "id": "cc4edd47bb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 730us/step - loss: 0.0164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x289890fe9d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_mean_squared_error(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)\n",
    "\n",
    "# We need to one-hot encode the labels to use MSE\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25b9fa7941ca"
   },
   "source": [
    "`y_true` 및 `y_pred` 이외의 매개 변수를 사용하는 손실 함수가 필요한 경우 `tf.keras.losses.Loss` 클래스를 서브 클래스 화하고 다음 두 메소드를 구현할 수 있습니다.\n",
    "\n",
    "- `__init__(self)` : 손실 함수 호출 중에 전달할 매개 변수를 승인합니다.\n",
    "- `call(self, y_true, y_pred)` : 목표 (y_true)와 모델 예측 (y_pred)을 사용하여 모델의 손실을 계산\n",
    "\n",
    "평균 제곱 오차를 사용하려고하지만 예측 값을 0.5에서 멀어지게하는 용어가 추가되었다고 가정 해 보겠습니다 (우리는 범주 형 목표가 원-핫 인코딩되고 0과 1 사이의 값을 취하는 것으로 가정). 이렇게하면 모델이 너무 자신감이없는 인센티브가 생겨 과적 합을 줄이는 데 도움이 될 수 있습니다 (시도 할 때까지 작동하는지 알 수 없음).\n",
    "\n",
    "방법은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:02.553096Z",
     "iopub.status.busy": "2021-04-07T17:59:02.552526Z",
     "iopub.status.idle": "2021-04-07T17:59:04.353462Z",
     "shell.execute_reply": "2021-04-07T17:59:04.353833Z"
    },
    "id": "b09463a8c568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 734us/step - loss: 0.0383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2898d6d1c10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
    "        return mse + reg * self.regularization_factor\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2141cc075a6"
   },
   "source": [
    "### 맞춤 측정 항목\n",
    "\n",
    "API의 일부가 아닌 메트릭이 필요한 경우 `tf.keras.metrics.Metric` 클래스를 서브 클래 싱하여 사용자 지정 메트릭을 쉽게 만들 수 있습니다. 4 가지 방법을 구현해야합니다.\n",
    "\n",
    "- `__init__(self)` . 여기서 메트릭에 대한 상태 변수를 만듭니다.\n",
    "- `update_state(self, y_true, y_pred, sample_weight=None)` 대상 y_true 및 모델 예측 y_pred를 사용하여 상태 변수를 업데이트합니다.\n",
    "- `result(self)` : 상태 변수를 사용하여 최종 결과를 계산합니다.\n",
    "- `reset_states(self)` : 메트릭의 상태를 다시 초기화합니다.\n",
    "\n",
    "경우에 따라 결과 계산이 매우 비싸고 주기적으로 만 수행되기 때문에 상태 업데이트와 결과 계산은 각각 `update_state()` 와 `result()` 에서 별도로 유지됩니다.\n",
    "\n",
    "다음은 `CategoricalTruePositives` 메트릭을 구현하는 방법을 보여주는 간단한 예제입니다.이 메트릭은 주어진 클래스에 속하는 것으로 올바르게 분류 된 샘플 수를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:04.363314Z",
     "iopub.status.busy": "2021-04-07T17:59:04.362654Z",
     "iopub.status.idle": "2021-04-07T17:59:09.979834Z",
     "shell.execute_reply": "2021-04-07T17:59:09.980190Z"
    },
    "id": "05d6a6e7022d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 1s 726us/step - loss: 0.3347 - categorical_true_positives: 45260.0000\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 731us/step - loss: 0.1544 - categorical_true_positives: 47709.0000\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 739us/step - loss: 0.1139 - categorical_true_positives: 48292.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2898f8dfca0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    def reset_state(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.true_positives.assign(0.0)\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[CategoricalTruePositives()],\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bca8e959cda"
   },
   "source": [
    "### 표준 서명에 맞지 않는 손실 및 메트릭 처리하기\n",
    "\n",
    "거의 대부분의 손실과 메트릭은 `y_true` 및 `y_pred`에서 계산할 수 있습니다(여기서 `y_pred`가 모델의 출력). 그러나 모두가 그런 것은 아닙니다. 예를 들어, 정규화 손실은 레이어의 활성화만 요구할 수 있으며(이 경우 대상이 없음) 이 활성화는 모델 출력이 아닐 수 있습니다.\n",
    "\n",
    "이러한 경우 사용자 정의 레이어의 호출 메서드 내에서 `self.add_loss(loss_value)`를 호출할 수 있습니다. 이러한 방식으로 추가된 손실은 훈련 중 \"주요\" 손실(`compile()`로 전달되는 손실)에 추가됩니다. 다음은 활동 정규화를 추가하는 간단한 예입니다. 참고로 활동 정규화는 모든 Keras 레이어에 내장되어 있으며 이 레이어는 구체적인 예를 제공하기 위한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:09.989008Z",
     "iopub.status.busy": "2021-04-07T17:59:09.988416Z",
     "iopub.status.idle": "2021-04-07T17:59:12.011691Z",
     "shell.execute_reply": "2021-04-07T17:59:12.011174Z"
    },
    "id": "b494d47437a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 723us/step - loss: 2.5564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28991a9a7c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs) # (None,784)(784,64) => (None,64)\n",
    "\n",
    "# Insert activity regularization as a layer\n",
    "x = ActivityRegularizationLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# The displayed loss will be much higher than before\n",
    "# due to the regularization component.\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaebb5829011"
   },
   "source": [
    "`add_metric()` 사용하여 메트릭 값 로깅에 대해 동일한 작업을 수행 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:12.021377Z",
     "iopub.status.busy": "2021-04-07T17:59:12.019956Z",
     "iopub.status.idle": "2021-04-07T17:59:14.167067Z",
     "shell.execute_reply": "2021-04-07T17:59:14.167421Z"
    },
    "id": "aa58091be092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 736us/step - loss: 0.3336 - std_of_activation: 0.9419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28992c68100>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MetricLoggingLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # The `aggregation` argument defines\n",
    "        # how to aggregate the per-batch values\n",
    "        # over each epoch:\n",
    "        # in this case we simply average them.\n",
    "        self.add_metric(\n",
    "            keras.backend.std(inputs), name=\"std_of_activation\", aggregation=\"mean\"\n",
    "        )\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert std logging as a layer.\n",
    "x = MetricLoggingLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3c18154d057"
   },
   "source": [
    "[Functional API](https://www.tensorflow.org/guide/keras/functional/) 에서 `model.add_loss(loss_tensor)` 또는 `model.add_metric(metric_tensor, name, aggregation)` 호출 할 수도 있습니다.\n",
    "\n",
    "다음은 간단한 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:14.176154Z",
     "iopub.status.busy": "2021-04-07T17:59:14.175268Z",
     "iopub.status.idle": "2021-04-07T17:59:16.355388Z",
     "shell.execute_reply": "2021-04-07T17:59:16.354905Z"
    },
    "id": "0e19afe78b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 758us/step - loss: 2.5278 - std_of_activation: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28995ed6c40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b06d48035369"
   },
   "source": [
    "`add_loss()` 를 통해 손실을 전달하면 모델에는 이미 손실이 있으므로 손실 함수없이 `compile()` 을 호출 할 수 있습니다.\n",
    "\n",
    "다음 `LogisticEndpoint` 레이어를 생각해 보겠습니다. 이 레이어는 입력으로 targets 및 logits를 받아들이고 `add_loss()`를 통해 교차 엔트로피 손실을 추적합니다. 또한 `add_metric()`를 통해 분류 정확도도 추적합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.361776Z",
     "iopub.status.busy": "2021-04-07T17:59:16.361194Z",
     "iopub.status.idle": "2021-04-07T17:59:16.362990Z",
     "shell.execute_reply": "2021-04-07T17:59:16.363332Z"
    },
    "id": "d56d2c504258"
   },
   "outputs": [],
   "source": [
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Log accuracy as a metric and add it\n",
    "        # to the layer using `self.add_metric()`.\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "\n",
    "        # Return the inference-time prediction tensor (for `.predict()`).\n",
    "        return tf.nn.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0698f3c98cbe"
   },
   "source": [
    "다음과 같이 `loss` 인수없이 컴파일 된 두 개의 입력 (입력 데이터 및 대상)이있는 모델에서 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.372039Z",
     "iopub.status.busy": "2021-04-07T17:59:16.370993Z",
     "iopub.status.idle": "2021-04-07T17:59:16.746912Z",
     "shell.execute_reply": "2021-04-07T17:59:16.747257Z"
    },
    "id": "0f6842f2bbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step - loss: 1.0006 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28996018fa0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
    "targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "logits = keras.layers.Dense(10)(inputs)\n",
    "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n",
    "\n",
    "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "model.compile(optimizer=\"adam\")  # No loss argument!\n",
    "\n",
    "data = {\n",
    "    \"inputs\": np.random.random((3, 3)),\n",
    "    \"targets\": np.random.random((3, 10)),\n",
    "}\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "328b021aa6b8"
   },
   "source": [
    "다중 입력 모델 교육에 대한 자세한 내용은 **다중 입력, 다중 출력 모델로 데이터 전달** 섹션을 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0536882b969c"
   },
   "source": [
    "### 유효성 검사 홀드아웃 세트를 자동으로 분리하기\n",
    "\n",
    "본 첫 번째 엔드 투 엔드 예제에서, 우리는 `validation_data` 인수를 사용하여 NumPy 배열의 튜플 `(x_val, y_val)` 을 모델에 전달하여 각 에포크의 끝에서 유효성 검증 손실 및 유효성 검증 메트릭을 평가합니다.\n",
    "\n",
    "또 다른 옵션: 인수 `validation_split`를 사용하여 유효성 검사 목적으로 훈련 데이터의 일부를 자동으로 예약할 수 있습니다. 인수 값은 유효성 검사를 위해 예약할 데이터 비율을 나타내므로 0보다 크고 1보다 작은 값으로 설정해야 합니다. 예를 들어, `validation_split=0.2`는 \"유효성 검사를 위해 데이터의 20%를 사용\"한다는 의미이고`validation_split=0.6`은 \"유효성 검사를 위해 데이터의 60%를 사용\"한다는 의미입니다.\n",
    "\n",
    "유효성을 계산하는 방법은 셔플 링 전에 맞춤 호출로 수신 한 배열의 마지막 x % 샘플을 가져 오는 것입니다.\n",
    "\n",
    "NumPy 데이터를 학습 할 때 `validation_split` 만 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.754009Z",
     "iopub.status.busy": "2021-04-07T17:59:16.753094Z",
     "iopub.status.idle": "2021-04-07T17:59:18.729991Z",
     "shell.execute_reply": "2021-04-07T17:59:18.729293Z"
    },
    "id": "232fd59c751b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 947us/step - loss: 0.3616 - sparse_categorical_accuracy: 0.8980 - val_loss: 0.2142 - val_sparse_categorical_accuracy: 0.9357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x289960ffd90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42969af7ce01"
   },
   "source": [
    "## tf.data 데이터 세트의 교육 및 평가\n",
    "\n",
    "앞서 몇 단락에 걸쳐 손실, 메트릭 및 옵티마이저를 처리하는 방법을 살펴보았으며, 데이터가 NumPy 배열로 전달될 때 fit에서 `validation_data` 및 `validation_split` 인수를 사용하는 방법도 알아보았습니다.\n",
    "\n",
    "이제 데이터가 `tf.data.Dataset` 객체의 형태로 제공되는 경우를 살펴 보겠습니다.\n",
    "\n",
    "`tf.data` API는 빠르고 확장 가능한 방식으로 데이터를 로드하고 사전 처리하기 위한 TensorFlow 2.0의 유틸리티 세트입니다.\n",
    "\n",
    "`Datasets` 생성에 대한 자세한 설명은 [tf.data 설명서](https://www.tensorflow.org/guide/data)를 참조하세요.\n",
    "\n",
    "`Dataset` 인스턴스를 메서드 `fit()`, `evaluate()` 및 `predict()`로 직접 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[2. 2. 5. 0. 5. 0. 9. 7. 7. 1. 9. 5. 7. 7. 9. 7. 5. 5. 5. 0. 6. 0. 5. 9.\n",
      " 5. 3. 4. 6. 1. 3. 7. 0. 3. 1. 5. 6. 1. 7. 7. 1. 4. 7. 7. 7. 4. 4. 3. 6.\n",
      " 0. 4. 8. 2. 8. 7. 2. 5. 4. 3. 6. 2. 6. 0. 9. 1.], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "for data in train_dataset:\n",
    "    print(data[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:18.737374Z",
     "iopub.status.busy": "2021-04-07T17:59:18.736671Z",
     "iopub.status.idle": "2021-04-07T17:59:25.389166Z",
     "shell.execute_reply": "2021-04-07T17:59:25.388563Z"
    },
    "id": "3bf4ded224f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 1s 866us/step - loss: 0.3390 - sparse_categorical_accuracy: 0.9037\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 873us/step - loss: 0.1638 - sparse_categorical_accuracy: 0.9519\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 868us/step - loss: 0.1200 - sparse_categorical_accuracy: 0.9641\n",
      "Evaluate\n",
      "157/157 [==============================] - 0s 632us/step - loss: 0.1256 - sparse_categorical_accuracy: 0.9620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.12560932338237762,\n",
       " 'sparse_categorical_accuracy': 0.9620000123977661}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# First, let's create a training Dataset instance.\n",
    "# For the sake of our example, we'll use the same MNIST data as before.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Now we get a test dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Since the dataset already takes care of batching,\n",
    "# we don't pass a `batch_size` argument.\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "421d16914ce3"
   },
   "source": [
    "데이터세트는 각 epoch의 끝에서 재설정되므로 다음 epoch에서 재사용할 수 있습니다.\n",
    "\n",
    "이 데이터세트의 특정 배치 수에 대해서만 훈련을 실행하려면 다음 epoch로 이동하기 전에 이 데이터세트를 사용하여 모델이 실행해야 하는 훈련 단계의 수를 지정하는 `steps_per_epoch` 인수를 전달할 수 있습니다.\n",
    "\n",
    "이렇게 하면 각 epoch가 끝날 때 데이터세트가 재설정되지 않고 다음 배치를 계속 가져오게 됩니다. 무한 반복되는 데이터세트가 아니라면 결국 데이터세트의 데이터가 고갈됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:25.395575Z",
     "iopub.status.busy": "2021-04-07T17:59:25.394783Z",
     "iopub.status.idle": "2021-04-07T17:59:26.675941Z",
     "shell.execute_reply": "2021-04-07T17:59:26.675448Z"
    },
    "id": "273c5dff16b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 0s 888us/step - loss: 0.7766 - sparse_categorical_accuracy: 0.8030\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 848us/step - loss: 0.3716 - sparse_categorical_accuracy: 0.8914\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 829us/step - loss: 0.3163 - sparse_categorical_accuracy: 0.9056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28998432910>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "model.fit(train_dataset, epochs=3 , steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2dcd180da7b"
   },
   "source": [
    "### 유효성 검사 데이터 집합 사용\n",
    "\n",
    "`fit()` 에서 `Dataset` 인스턴스를 `validation_data` 인수로 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:26.682749Z",
     "iopub.status.busy": "2021-04-07T17:59:26.681981Z",
     "iopub.status.idle": "2021-04-07T17:59:29.751000Z",
     "shell.execute_reply": "2021-04-07T17:59:29.751364Z"
    },
    "id": "bf4f3d78e69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3235 - sparse_categorical_accuracy: 0.9087 - val_loss: 0.1932 - val_sparse_categorical_accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2899863d6a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e7f0ebf5f1d"
   },
   "source": [
    "각 시대가 끝날 때 모델은 유효성 검사 데이터 집합을 반복하고 유효성 검사 손실 및 유효성 검사 메트릭을 계산합니다.\n",
    "\n",
    "이 데이터세트의 특정 배치 수에 대해서만 유효성 검사를 실행하려면 유효성 검사를 중단하고 다음 epoch로 넘어가기 전에 유효성 검사 데이터세트에서 모델이 실행해야 하는 유효성 검사 단계의 수를 지정하는 `validation_steps` 인수를 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:29.758316Z",
     "iopub.status.busy": "2021-04-07T17:59:29.757458Z",
     "iopub.status.idle": "2021-04-07T17:59:32.372341Z",
     "shell.execute_reply": "2021-04-07T17:59:32.372720Z"
    },
    "id": "f47342fed069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 974us/step - loss: 0.3338 - sparse_categorical_accuracy: 0.9063 - val_loss: 0.3127 - val_sparse_categorical_accuracy: 0.9187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2898d6b5d90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,\n",
    "    # Only run validation using the first 10 batches of the dataset\n",
    "    # using the `validation_steps` argument\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67b4418e9f26"
   },
   "source": [
    "유효성 검사 데이터 세트는 사용 후마다 재설정되므로 항상 에포크에서 에포크까지 동일한 샘플을 평가하게됩니다.\n",
    "\n",
    "인수 `validation_split`(훈련 데이터로부터 홀드아웃 세트 생성)는 `Dataset` 객체로 훈련할 때는 지원되지 않는데, 이를 위해서는 데이터세트 샘플을 인덱싱할 수 있어야 하지만 `Dataset` API에서는 일반적으로 이것이 불가능하기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8160beb766a0"
   },
   "source": [
    "## 지원되는 다른 입력 형식\n",
    "\n",
    "NumPy 배열, 즉시 실행 텐서 및 TensorFlow `Datasets` 외에도 Pandas 데이터프레임을 사용하거나 데이터 및 레이블의 배치를 생성하는 Python 생성기에서 Keras 모델을 훈련할 수 있습니다.\n",
    "\n",
    "특히, `keras.utils.Sequence` 클래스는 멀티스레딩을 인식하고 셔플이 가능한 Python 데이터 생성기를 빌드하기 위한 간단한 인터페이스를 제공합니다.\n",
    "\n",
    "일반적으로 다음을 사용하는 것이 좋습니다.\n",
    "\n",
    "- 데이터가 작고 메모리에 맞는 경우 NumPy 입력 데이터\n",
    "- 큰 데이터세트가 있고 분산 훈련을 수행해야 하는 경우 `Dataset` 객체\n",
    "- 큰 데이터세트가 있고 TensorFlow에서 수행할 수 없는 많은 사용자 정의 Python 측 처리를 수행해야 하는 경우(예: 데이터 로드 또는 사전 처리를 위해 외부 라이브러리에 의존하는 경우) `Sequence` 객체\n",
    "\n",
    "## `keras.utils.Sequence` 객체를 입력으로 사용하기\n",
    "\n",
    "`keras.utils.Sequence`는 두 가지 중요한 속성을 가진 Python 생성기를 얻기 위해 하위 클래스화를 수행할 수 있는 유틸리티입니다.\n",
    "\n",
    "- 멀티 프로세싱과 잘 작동합니다.\n",
    "- 셔플할 수 있습니다(예: `fit()`에서 `shuffle=True`를 전달하는 경우).\n",
    "\n",
    "`Sequence` 는 두 가지 방법을 구현해야합니다.\n",
    "\n",
    "- `__getitem__`\n",
    "- `__len__`\n",
    "\n",
    "`__getitem__` 메소드는 완전한 배치를 리턴해야합니다. 신기원 사이의 데이터 세트를 수정하려면 `on_epoch_end` 구현할 수 있습니다.\n",
    "\n",
    "간단한 예를 들자면 다음과 같습니다.\n",
    "\n",
    "```python\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "# Here, `filenames` is list of path to the images\n",
    "# and `labels` are the associated labels.\n",
    "\n",
    "class CIFAR10Sequence(Sequence):\n",
    "    def __init__(self, filenames, labels, batch_size):\n",
    "        self.filenames, self.labels = filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([\n",
    "            resize(imread(filename), (200, 200))\n",
    "               for filename in batch_x]), np.array(batch_y)\n",
    "\n",
    "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
    "model.fit(sequence, epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a28343b1967"
   },
   "source": [
    "## 샘플 가중치 및 클래스 가중치 사용\n",
    "\n",
    "기본 설정을 사용하면 샘플의 무게가 데이터 세트의 빈도에 따라 결정됩니다. 샘플 빈도와 관계없이 데이터에 가중치를 부여하는 방법에는 두 가지가 있습니다.\n",
    "\n",
    "- 클래스 가중치\n",
    "- 샘플 무게"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f234a9a75b6d"
   },
   "source": [
    "### 클래스 가중치\n",
    "\n",
    "이 가중치는 `Model.fit()`에 대한 `class_weight` 인수로 사전을 전달하여 설정합니다. 이 사전은 클래스 인덱스를 이 클래스에 속한 샘플에 사용해야 하는 가중치에 매핑합니다.\n",
    "\n",
    "이 방법은 샘플링을 다시 수행하지 않고 클래스의 균형을 맞추거나 특정 클래스에 더 중요한 모델을 훈련시키는 데 사용할 수 있습니다.\n",
    "\n",
    "예를 들어, 데이터에서 클래스 \"0\"이 클래스 \"1\"로 표시된 것의 절반인 경우 `Model.fit(..., class_weight={0: 1., 1: 0.5})`을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9929d26d91b8"
   },
   "source": [
    "다음은 클래스 #5(MNIST 데이터세트에서 숫자 \"5\")의 올바른 분류에 더 많은 중요성을 두도록 클래스 가중치 또는 샘플 가중치를 사용하는 NumPy 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:32.379985Z",
     "iopub.status.busy": "2021-04-07T17:59:32.379268Z",
     "iopub.status.idle": "2021-04-07T17:59:34.552093Z",
     "shell.execute_reply": "2021-04-07T17:59:34.552450Z"
    },
    "id": "f1844f2329a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with class weight\n",
      "782/782 [==============================] - 1s 799us/step - loss: 0.3882 - sparse_categorical_accuracy: 0.9006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x289962195b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: 1.0,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    # Set weight \"2\" for class \"5\",\n",
    "    # making this class 2x more important\n",
    "    5: 2.0,\n",
    "    6: 1.0,\n",
    "    7: 1.0,\n",
    "    8: 1.0,\n",
    "    9: 1.0,\n",
    "}\n",
    "\n",
    "print(\"Fit with class weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce27221fad08"
   },
   "source": [
    "### 샘플 무게\n",
    "\n",
    "세밀한 제어를 위해 또는 분류기를 작성하지 않는 경우 \"샘플 가중치\"를 사용할 수 있습니다.\n",
    "\n",
    "- NumPy 데이터에서 학습하는 경우 : `sample_weight` 인수를 `Model.fit()` .\n",
    "- `tf.data` 또는 다른 종류의 반복자에서 훈련 할 때 : Yield `(input_batch, label_batch, sample_weight_batch)` 튜플.\n",
    "\n",
    "\"샘플 가중치\"배열은 배치에서 각 샘플이 총 손실을 계산하는 데 필요한 가중치를 지정하는 숫자 배열입니다. 불균형 분류 문제 (거의 보이지 않는 클래스에 더 많은 가중치를 부여하는 아이디어)에 일반적으로 사용됩니다.\n",
    "\n",
    "사용 된 가중치가 1과 0 인 경우, 어레이는 손실 함수에 대한 *마스크* 로 사용될 수 있습니다 (전체 손실에 대한 특정 샘플의 기여를 완전히 버림)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:34.557087Z",
     "iopub.status.busy": "2021-04-07T17:59:34.556528Z",
     "iopub.status.idle": "2021-04-07T17:59:41.179312Z",
     "shell.execute_reply": "2021-04-07T17:59:41.178824Z"
    },
    "id": "f9819d647793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with sample weight\n",
      "782/782 [==============================] - 1s 755us/step - loss: 0.3830 - sparse_categorical_accuracy: 0.8992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x289988c2b80>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "print(\"Fit with sample weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eae5837c5f56"
   },
   "source": [
    "일치하는 `Dataset` 예는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:41.184161Z",
     "iopub.status.busy": "2021-04-07T17:59:41.183589Z",
     "iopub.status.idle": "2021-04-07T17:59:43.788537Z",
     "shell.execute_reply": "2021-04-07T17:59:43.788025Z"
    },
    "id": "c870f3f0c66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 902us/step - loss: 0.3798 - sparse_categorical_accuracy: 0.8998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x289989d8e80>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "# Create a Dataset that includes sample weights\n",
    "# (3rd element in the return tuple).\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
    "\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3963bfa348b0"
   },
   "source": [
    "## 다중 입력, 다중 출력 모델로 데이터 전달\n",
    "\n",
    "이전 예에서는 단일 입력(형상 `(764,)`의 텐서)과 단일 출력(형상 `(10,)`의 예측 텐서)이 있는 모델을 고려했습니다. 그렇다면 입력 또는 출력이 여러 개인 모델은 어떨까요?\n",
    "\n",
    "shape `(32, 32, 3)` ( `(height, width, channels)` 입력과 shape `(None, 10)` 의 시계열 입력 `(timesteps, features)` 하십시오. 우리의 모델은이 입력들의 조합으로부터 계산 된 두 개의 출력을 가질 것입니다 : \"점수\"(모양 `(1,)` )와 5 개의 클래스 (모양 `(5,)` )에 대한 확률 분포."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:43.798671Z",
     "iopub.status.busy": "2021-04-07T17:59:43.797137Z",
     "iopub.status.idle": "2021-04-07T17:59:43.836889Z",
     "shell.execute_reply": "2021-04-07T17:59:43.837258Z"
    },
    "id": "5f958449a057"
   },
   "outputs": [],
   "source": [
    "image_input = keras.Input(shape=(32, 32, 3), name=\"img_input\")\n",
    "timeseries_input = keras.Input(shape=(None, 10), name=\"ts_input\")\n",
    "\n",
    "x1 = layers.Conv2D(3, 3)(image_input)  # (None,32,32,3)(3,3,3,3)\n",
    "x1 = layers.GlobalMaxPooling2D()(x1)   # (None,30,30,3)\n",
    "                                       # (None,3)\n",
    "\n",
    "x2 = layers.Conv1D(3, 3)(timeseries_input) # (None,None,10)(3,10,3)\n",
    "x2 = layers.GlobalMaxPooling1D()(x2)       # (None,None,3)\n",
    "                                           # (None,3)\n",
    "\n",
    "x = layers.concatenate([x1, x2])  # (None,3) (None,3)\n",
    "                                  # (None,6)\n",
    "\n",
    "score_output = layers.Dense(1, name=\"score_output\")(x)  # (None,6)(6,1)\n",
    "class_output = layers.Dense(5, name=\"class_output\")(x)  # (None,6)(6,5)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[image_input, timeseries_input], outputs=[score_output, class_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df3ed34fe78b"
   },
   "source": [
    "이 모델을 플로팅하여 여기서 수행중인 작업을 명확하게 확인할 수 있습니다 (플롯에 표시된 셰이프는 샘플 별 셰이프가 아니라 배치 셰이프 임)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:43.841632Z",
     "iopub.status.busy": "2021-04-07T17:59:43.840966Z",
     "iopub.status.idle": "2021-04-07T17:59:43.997553Z",
     "shell.execute_reply": "2021-04-07T17:59:43.997939Z"
    },
    "id": "ac8c1baca9e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d979e89b335"
   },
   "source": [
    "컴파일 타임에 손실 함수를 목록으로 전달하여 출력마다 다른 손실을 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.008729Z",
     "iopub.status.busy": "2021-04-07T17:59:44.008083Z",
     "iopub.status.idle": "2021-04-07T17:59:44.020566Z",
     "shell.execute_reply": "2021-04-07T17:59:44.020024Z"
    },
    "id": "9655c0084d70"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5fc73405283"
   },
   "source": [
    "모델에 단일 손실 함수만 전달하는 경우, 모든 출력에 동일한 손실 함수가 적용됩니다(여기서는 적합하지 않음).\n",
    "\n",
    "메트릭의 경우도 마찬가지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.031233Z",
     "iopub.status.busy": "2021-04-07T17:59:44.030430Z",
     "iopub.status.idle": "2021-04-07T17:59:44.054558Z",
     "shell.execute_reply": "2021-04-07T17:59:44.054914Z"
    },
    "id": "b4c0c6c564bc"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    "    metrics=[\n",
    "        [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        [keras.metrics.CategoricalAccuracy()],\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dd9fb0343cc"
   },
   "source": [
    "출력 레이어에 이름을 지정 했으므로 dict를 통해 출력 당 손실 및 메트릭을 지정할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.064527Z",
     "iopub.status.busy": "2021-04-07T17:59:44.063850Z",
     "iopub.status.idle": "2021-04-07T17:59:44.083742Z",
     "shell.execute_reply": "2021-04-07T17:59:44.083134Z"
    },
    "id": "42cb75110fc3"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfd95ac0dd8b"
   },
   "source": [
    "출력이 두 개 이상인 경우 명시적 이름과 사전을 사용하는 것이 좋습니다.\n",
    "\n",
    "`loss_weights` 인수를 사용하여 출력별 손실에 서로 다른 가중치를 부여할 수 있습니다(예를 들어, 클래스 손실에 2x의 중요도를 부여하여 이 예에서 \"score\" 손실에 우선권을 줄 수 있음)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.093695Z",
     "iopub.status.busy": "2021-04-07T17:59:44.093100Z",
     "iopub.status.idle": "2021-04-07T17:59:44.112359Z",
     "shell.execute_reply": "2021-04-07T17:59:44.112739Z"
    },
    "id": "23a71e5f5227"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    "    loss_weights={\"score_output\": 2.0, \"class_output\": 1.0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "367f598029e7"
   },
   "source": [
    "이러한 출력이 예측 용이지만 훈련 용이 아닌 경우 특정 출력에 대한 손실을 계산하지 않도록 선택할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.121160Z",
     "iopub.status.busy": "2021-04-07T17:59:44.120554Z",
     "iopub.status.idle": "2021-04-07T17:59:44.130318Z",
     "shell.execute_reply": "2021-04-07T17:59:44.130734Z"
    },
    "id": "6d51aa372ef4"
   },
   "outputs": [],
   "source": [
    "# List loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[None, keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Or dict loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\"class_output\": keras.losses.CategoricalCrossentropy()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8314a8b3a7c7"
   },
   "source": [
    "적합하게 다중 입력 또는 다중 출력 모델에 데이터를 전달하는 것은 컴파일에서 손실 함수를 지정하는 것과 유사한 방식으로 작동합니다. **NumPy 배열 목록을** 전달할 수 있습니다 (손실 함수를 수신 한 출력에 1 : 1 매핑). **출력 이름을 NumPy 배열에 매핑합니다** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.135391Z",
     "iopub.status.busy": "2021-04-07T17:59:44.134811Z",
     "iopub.status.idle": "2021-04-07T17:59:46.741893Z",
     "shell.execute_reply": "2021-04-07T17:59:46.742292Z"
    },
    "id": "0539da84328b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 17.7049 - score_output_loss: 0.6293 - class_output_loss: 17.0756\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 16.7566 - score_output_loss: 0.4036 - class_output_loss: 16.3529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x289a83d8cd0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Generate dummy NumPy data\n",
    "img_data = np.random.random_sample(size=(100, 32, 32, 3))\n",
    "ts_data = np.random.random_sample(size=(100, 20, 10))\n",
    "score_targets = np.random.random_sample(size=(100, 1))\n",
    "class_targets = np.random.random_sample(size=(100, 5))\n",
    "\n",
    "# Fit on lists\n",
    "model.fit([img_data, ts_data], [score_targets, class_targets], batch_size=32, epochs=1)\n",
    "\n",
    "# Alternatively, fit on dicts\n",
    "model.fit(\n",
    "    {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "    {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e53eda8e1399"
   },
   "source": [
    "`Dataset` 사용 사례는 다음과 같습니다. NumPy 배열에서 수행 한 것과 유사하게 `Dataset` 은 튜플 튜플을 반환해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:46.752664Z",
     "iopub.status.busy": "2021-04-07T17:59:46.752034Z",
     "iopub.status.idle": "2021-04-07T17:59:47.185670Z",
     "shell.execute_reply": "2021-04-07T17:59:47.186035Z"
    },
    "id": "4df41a12ed2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4597 - score_output_loss: 0.3262 - class_output_loss: 17.1335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28996026f10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "        {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    )\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38ebf30ce6ac"
   },
   "source": [
    "## 콜백 사용하기\n",
    "\n",
    "Keras의 콜백은 훈련 중 다른 시점(epoch의 시작, 배치의 끝, epoch의 끝 등)에서 호출되며 다음과 같은 동작을 구현하는 데 사용할 수 있는 객체입니다.\n",
    "\n",
    "- 훈련 중 서로 다른 시점에서 유효성 검사 수행(내장된 epoch당 유효성 검사에서 더욱 확장)\n",
    "- 정기적으로 또는 특정 정확도 임계값을 초과할 때 모델 검사점 설정\n",
    "- 훈련이 정체 된 것처럼 보일 때 모델의 학습 속도 변경\n",
    "- 훈련이 정체 된 것처럼 보일 때 최상위 레이어의 미세 조정\n",
    "- 교육이 종료되거나 특정 성능 임계 값을 초과 한 경우 전자 메일 또는 인스턴트 메시지 알림 보내기\n",
    "- 기타\n",
    "\n",
    "콜백은 `fit()` 에 대한 호출에 목록으로 전달 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:47.193545Z",
     "iopub.status.busy": "2021-04-07T17:59:47.192522Z",
     "iopub.status.idle": "2021-04-07T17:59:57.855887Z",
     "shell.execute_reply": "2021-04-07T17:59:57.855277Z"
    },
    "id": "15036ddbee42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 1s 952us/step - loss: 0.3698 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.2306 - val_sparse_categorical_accuracy: 0.9308\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 1s 862us/step - loss: 0.1738 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.1913 - val_sparse_categorical_accuracy: 0.9402\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 1s 864us/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.1638 - val_sparse_categorical_accuracy: 0.9484\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 1s 872us/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1424 - val_sparse_categorical_accuracy: 0.9570\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 1s 883us/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9754 - val_loss: 0.1313 - val_sparse_categorical_accuracy: 0.9621\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 1s 883us/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.1564 - val_sparse_categorical_accuracy: 0.9560\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 1s 872us/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.1270 - val_sparse_categorical_accuracy: 0.9633\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x289a96bfd90>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,   # 0.01\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "303815509732"
   },
   "source": [
    "### 많은 내장 콜백을 사용할 수 있습니다\n",
    "\n",
    "- `ModelCheckpoint` : 주기적으로 모델을 저장합니다.\n",
    "- `EarlyStopping`: 훈련이 더 이상 유효성 검사 메트릭을 개선하지 못하는 경우 훈련을 중단합니다.\n",
    "- `TensorBoard` : 시각화 할 수 있습니다 정기적으로 쓰기 모델 로그 [TensorBoard](https://www.tensorflow.org/tensorboard) (섹션 \"시각화\"에서 자세한 내용).\n",
    "- `CSVLogger` : 손실 및 메트릭 데이터를 CSV 파일로 스트리밍합니다.\n",
    "- 기타\n",
    "\n",
    "전체 목록은 [콜백 설명서](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/) 를 참조하십시오.\n",
    "\n",
    "### 자신의 콜백 작성\n",
    "\n",
    "기본 클래스 `keras.callbacks.Callback` 을 확장하여 사용자 정의 콜백을 작성할 수 있습니다. 콜백은 클래스 속성 `self.model` 통해 연관된 모델에 액세스 할 수 있습니다.\n",
    "\n",
    "[사용자 정의 콜백을 작성하기 위한 전체 가이드](https://www.tensorflow.org/guide/keras/custom_callback/)를 꼭 읽어보세요. 다음은 훈련 중 배치별 손실 값 목록을 저장하는 간단한 예입니다.\n",
    "\n",
    "다음은 훈련 중 배치 별 손실 값 목록을 저장하는 간단한 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:57.860674Z",
     "iopub.status.busy": "2021-04-07T17:59:57.860106Z",
     "iopub.status.idle": "2021-04-07T17:59:57.862542Z",
     "shell.execute_reply": "2021-04-07T17:59:57.862070Z"
    },
    "id": "b265d36ce608"
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ee672524987"
   },
   "source": [
    "## 모델 검사점 설정하기\n",
    "\n",
    "상대적으로 큰 데이터세트에 대한 모델을 훈련시킬 때는 모델의 검사점을 빈번하게 저장하는 것이 중요합니다.\n",
    "\n",
    "이를 수행하는 가장 쉬운 방법은 `ModelCheckpoint` 콜백을 사용하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:57.870033Z",
     "iopub.status.busy": "2021-04-07T17:59:57.868836Z",
     "iopub.status.idle": "2021-04-07T18:00:02.043065Z",
     "shell.execute_reply": "2021-04-07T18:00:02.042601Z"
    },
    "id": "83614be57725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.3638 - sparse_categorical_accuracy: 0.8970\n",
      "Epoch 1: val_loss improved from inf to 0.22794, saving model to mymodel_1\n",
      "INFO:tensorflow:Assets written to: mymodel_1\\assets\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.3632 - sparse_categorical_accuracy: 0.8971 - val_loss: 0.2279 - val_sparse_categorical_accuracy: 0.9302\n",
      "Epoch 2/2\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1743 - sparse_categorical_accuracy: 0.9472\n",
      "Epoch 2: val_loss improved from 0.22794 to 0.18986, saving model to mymodel_2\n",
      "INFO:tensorflow:Assets written to: mymodel_2\\assets\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.1741 - sparse_categorical_accuracy: 0.9472 - val_loss: 0.1899 - val_sparse_categorical_accuracy: 0.9421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x289aa7effd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=\"mymodel_{epoch}\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f6afa36950c"
   },
   "source": [
    "`ModelCheckpoint` 콜백을 사용하여 내결함성을 구현할 수 있습니다. 훈련이 무작위로 중단 된 경우 모델의 마지막 저장된 상태에서 훈련을 다시 시작할 수있는 기능. 기본 예는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:02.050845Z",
     "iopub.status.busy": "2021-04-07T18:00:02.048933Z",
     "iopub.status.idle": "2021-04-07T18:00:11.144699Z",
     "shell.execute_reply": "2021-04-07T18:00:11.144180Z"
    },
    "id": "27ce92b2ad58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model\n",
      "  75/1563 [>.............................] - ETA: 1s - loss: 1.0920 - sparse_categorical_accuracy: 0.7142  INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.97\\assets\n",
      " 172/1563 [==>...........................] - ETA: 3s - loss: 0.7348 - sparse_categorical_accuracy: 0.8029INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.69\\assets\n",
      " 273/1563 [====>.........................] - ETA: 3s - loss: 0.5978 - sparse_categorical_accuracy: 0.8352INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.57\\assets\n",
      " 371/1563 [======>.......................] - ETA: 3s - loss: 0.5237 - sparse_categorical_accuracy: 0.8540INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.51\\assets\n",
      " 472/1563 [========>.....................] - ETA: 3s - loss: 0.4753 - sparse_categorical_accuracy: 0.8655INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.46\\assets\n",
      " 570/1563 [=========>....................] - ETA: 2s - loss: 0.4387 - sparse_categorical_accuracy: 0.8748INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.43\\assets\n",
      " 670/1563 [===========>..................] - ETA: 2s - loss: 0.4107 - sparse_categorical_accuracy: 0.8822INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.40\\assets\n",
      " 768/1563 [=============>................] - ETA: 2s - loss: 0.3889 - sparse_categorical_accuracy: 0.8879INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.38\\assets\n",
      " 872/1563 [===============>..............] - ETA: 2s - loss: 0.3699 - sparse_categorical_accuracy: 0.8938INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.36\\assets\n",
      " 969/1563 [=================>............] - ETA: 1s - loss: 0.3547 - sparse_categorical_accuracy: 0.8977INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.35\\assets\n",
      "1071/1563 [===================>..........] - ETA: 1s - loss: 0.3392 - sparse_categorical_accuracy: 0.9018INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.34\\assets\n",
      "1170/1563 [=====================>........] - ETA: 1s - loss: 0.3285 - sparse_categorical_accuracy: 0.9049INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.33\\assets\n",
      "1272/1563 [=======================>......] - ETA: 0s - loss: 0.3165 - sparse_categorical_accuracy: 0.9085INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.31\\assets\n",
      "1370/1563 [=========================>....] - ETA: 0s - loss: 0.3084 - sparse_categorical_accuracy: 0.9107INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.31\\assets\n",
      "1472/1563 [===========================>..] - ETA: 0s - loss: 0.3020 - sparse_categorical_accuracy: 0.9125INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.30\\assets\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2947 - sparse_categorical_accuracy: 0.9143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x289ab9e3fa0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Prepare a directory to store all the checkpoints.\n",
    "checkpoint_dir = \"./ckpt\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "\n",
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()\n",
    "\n",
    "\n",
    "model = make_or_restore_model()\n",
    "callbacks = [\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the saved model name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + \"/ckpt-loss={loss:.2f}\", save_freq=100\n",
    "    )\n",
    "]\n",
    "model.fit(x_train, y_train, epochs=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da3ab58d5235"
   },
   "source": [
    "또한 모델 저장 및 복원을 위해 자체 콜백을 작성하십시오.\n",
    "\n",
    "직렬화 및 저장에 대한 전체 안내서는 [모델 저장 및 직렬화 안내서를](https://www.tensorflow.org/guide/keras/save_and_serialize/) 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9342cc2ddba"
   },
   "source": [
    "## 학습 속도 일정 사용하기\n",
    "\n",
    "딥 러닝 모델을 훈련 할 때 일반적인 패턴은 훈련이 진행됨에 따라 점차적으로 학습을 줄이는 것입니다. 이것을 일반적으로 \"학습률 감소\"라고합니다.\n",
    "\n",
    "학습 붕괴 스케줄은 정적 인 (현재 에포크 또는 현재 배치 인덱스의 함수로서 미리 고정됨) 또는 동적 (모델의 현재 행동, 특히 검증 손실에 대응) 일 수있다.\n",
    "\n",
    "### 옵티마이저로 일정 전달하기\n",
    "\n",
    "옵티 마이저에서 schedule 객체를 `learning_rate` 인수로 전달하여 정적 학습 속도 감소 스케줄을 쉽게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:11.150053Z",
     "iopub.status.busy": "2021-04-07T18:00:11.149381Z",
     "iopub.status.idle": "2021-04-07T18:00:11.151800Z",
     "shell.execute_reply": "2021-04-07T18:00:11.151244Z"
    },
    "id": "684f0ab6d3de"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d742e44f535"
   },
   "source": [
    "`ExponentialDecay` , `PiecewiseConstantDecay` , `PolynomialDecay` 및 `InverseTimeDecay` 와 같은 몇 가지 기본 제공 일정을 사용할 수 있습니다.\n",
    "\n",
    "### 콜백을 사용하여 동적 학습 속도 일정 구현\n",
    "\n",
    "옵티마이저가 유효성 검사 메트릭에 액세스할 수 없으므로 이러한 일정 객체로는 동적 학습률 일정(예: 유효성 검사 손실이 더 이상 개선되지 않을 때 학습률 감소)을 달성할 수 없습니다.\n",
    "\n",
    "그러나 콜백은 유효성 검사 메트릭을 포함해 모든 메트릭에 액세스할 수 있습니다! 따라서 옵티마이저에서 현재 학습률을 수정하는 콜백을 사용하여 이 패턴을 달성할 수 있습니다. 실제로 이 부분이`ReduceLROnPlateau` 콜백으로 내장되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4a05f880175"
   },
   "source": [
    "## 훈련 중 손실 및 메트릭 시각화하기\n",
    "\n",
    "교육 중에 모델을 주시하는 가장 좋은 방법은 로컬에서 실행할 수있는 브라우저 기반 응용 프로그램 인 [TensorBoard](https://www.tensorflow.org/tensorboard) 를 사용하는 것입니다.\n",
    "\n",
    "- 교육 및 평가를위한 손실 및 지표의 라이브 플롯\n",
    "- (옵션) 레이어 활성화 히스토그램 시각화\n",
    "- (옵션) `Embedding` 레이어에서 학습한 포함된 공간의 3D 시각화\n",
    "\n",
    "pip와 함께 TensorFlow를 설치한 경우, 명령줄에서 TensorBoard를 시작할 수 있습니다.\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/full_path_to_your_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fcf386a1dad"
   },
   "source": [
    "### TensorBoard 콜백 사용하기\n",
    "\n",
    "TensorBoard를 Keras 모델 및 fit 메서드와 함께 사용하는 가장 쉬운 방법은 `TensorBoard` 콜백입니다.\n",
    "\n",
    "가장 간단한 경우로, 콜백에서 로그를 작성할 위치만 지정하면 바로 쓸 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:11.157400Z",
     "iopub.status.busy": "2021-04-07T18:00:11.156688Z",
     "iopub.status.idle": "2021-04-07T18:00:11.159760Z",
     "shell.execute_reply": "2021-04-07T18:00:11.159192Z"
    },
    "id": "f74247282ff6"
   },
   "outputs": [],
   "source": [
    "keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_logs\",\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    ")  # How often to write logs (default: once per epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50cd5f8631fd"
   },
   "source": [
    "자세한 내용 [`TensorBoard` 콜백 설명서](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/tensorboard/)를 참조하세요."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_and_evaluate.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
