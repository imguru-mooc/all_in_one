{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': padding_mask # 패딩 마스크 사용\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "      outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "          dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "      )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "#     return look_ahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 1. 1. 1. 1.]\n",
      "   [0. 1. 1. 1. 1.]\n",
      "   [0. 1. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[4, 0, 0, 2, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "        })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "            'mask': padding_mask # 패딩 마스크\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                  d_model, num_heads, dropout,\n",
    "                  name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9000, 128)\n",
      "(1, 9000, 128)\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "# Text(0.5, 0, 'Train Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 처음 설치 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.2.0-py3-none-any.whl (3.7 MB)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.14.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.24.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.11.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (20.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.19.2)\n",
      "Requirement already satisfied: six in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.50.2)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.26.0-py3-none-any.whl (47 kB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Collecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-5.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: future in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2020.6.20)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21500 sha256=0240545bb1bc6153f5f9225f16d710d030658e5e0ec06c5adaee543bebeba7f6\n",
      "  Stored in directory: c:\\users\\jikim\\appdata\\local\\pip\\cache\\wheels\\54\\aa\\01\\724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built promise\n",
      "Installing collected packages: promise, googleapis-common-protos, tensorflow-metadata, dill, importlib-resources, tensorflow-datasets\n",
      "Successfully installed dill-0.3.3 googleapis-common-protos-1.52.0 importlib-resources-5.0.0 promise-2.3 tensorflow-datasets-4.2.0 tensorflow-metadata-0.26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow-metadata 0.26.0 requires absl-py<0.11,>=0.9, but you'll have absl-py 0.11.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 업그레이드 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow_datasets in c:\\users\\jikim\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=18.1.0 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (20.3.0)\n",
      "Requirement already satisfied, skipping upgrade: future in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: promise in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.9\" in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (5.0.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-metadata in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.26.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: dill in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: absl-py in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.12.2 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.50.2)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2,>=1.52.0 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.52.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --user --upgrade tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8178]\n",
      "종료 토큰 번호 : [8179]\n",
      "단어 집합의 크기 : 8180\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임의의 질문 샘플을 정수 인코딩 : [5766, 611, 3509, 141, 685, 3747, 849]\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "기존 문장: 가스비 비싼데 감기 걸리겠어\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 ----> 가스\n",
      "611 ----> 비 \n",
      "3509 ----> 비싼\n",
      "141 ----> 데 \n",
      "685 ----> 감기 \n",
      "3747 ----> 걸리\n",
      "849 ----> 겠어\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기(shape) : (11823, 40)\n",
      "답변 데이터의 크기(shape) : (11823, 40)\n"
     ]
    }
   ],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8180, 256)\n",
      "(1, 8180, 256)\n"
     ]
    }
   ],
   "source": [
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 14s 52ms/step - loss: 1.5162 - accuracy: 0.0135\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 1.2421 - accuracy: 0.0486\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 1.0375 - accuracy: 0.0501\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.9314 - accuracy: 0.0535\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.8737 - accuracy: 0.0569\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.8080 - accuracy: 0.0612\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.7458 - accuracy: 0.0670\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.6766 - accuracy: 0.0753\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.5999 - accuracy: 0.0838\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.5112 - accuracy: 0.0935\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.4282 - accuracy: 0.1037\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 10s 51ms/step - loss: 0.3456 - accuracy: 0.1151\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.2710 - accuracy: 0.1274\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.1998 - accuracy: 0.1383\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.1447 - accuracy: 0.1474\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.1023 - accuracy: 0.1556\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0714 - accuracy: 0.1618\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 10s 51ms/step - loss: 0.0535 - accuracy: 0.1648\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0446 - accuracy: 0.1658\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0394 - accuracy: 0.1663\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0358 - accuracy: 0.1659\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0334 - accuracy: 0.1660\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0327 - accuracy: 0.1678\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0267 - accuracy: 0.1686\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0241 - accuracy: 0.1687\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0220 - accuracy: 0.1689\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 10s 51ms/step - loss: 0.0200 - accuracy: 0.1707\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0181 - accuracy: 0.1698\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0153 - accuracy: 0.1714\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.0148 - accuracy: 0.1721\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.0134 - accuracy: 0.1730\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 10s 51ms/step - loss: 0.0128 - accuracy: 0.1734\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0116 - accuracy: 0.1724\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.0113 - accuracy: 0.1718\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 10s 51ms/step - loss: 0.0102 - accuracy: 0.1736\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.0092 - accuracy: 0.1727\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0082 - accuracy: 0.1731\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.0092 - accuracy: 0.1727\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.0078 - accuracy: 0.1735\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0082 - accuracy: 0.1731\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0073 - accuracy: 0.1729\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0073 - accuracy: 0.1745\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0068 - accuracy: 0.1741\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0060 - accuracy: 0.1739\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0060 - accuracy: 0.1740\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0058 - accuracy: 0.1736\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0057 - accuracy: 0.1748\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 10s 51ms/step - loss: 0.0056 - accuracy: 0.1740\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 9s 51ms/step - loss: 0.0058 - accuracy: 0.1742\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 10s 51ms/step - loss: 0.0049 - accuracy: 0.1748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x173023cc4f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 날씨가 좋넹.\n",
      "Output: 좋은 사람이 찾아오려나봐요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"날씨가 좋넹.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 고민이 있어\n",
      "Output: 생각을 종이에 끄젹여여 보는게 도움이 될 수도 있어요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 너무 화가나\n",
      "Output: 그럴수록 당신이 힘들 거예요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 카페갈래?\n",
      "Output: 카페 가서 차 마셔도 돼요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"카페갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 게임하고싶당\n",
      "Output: 게임하세요 !\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하고싶당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 게임하자\n",
      "Output: 안 괜찮아도 돼요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
